---------

- [gans-awesome-applications](https://github.com/nashory/gans-awesome-applications)

----

<h2 id="gan-use-cases">GAN Use Cases</h2>
<ul>
<li><a href="https://arxiv.org/abs/1605.05396">Text to Image Generation</a></li>
<li><a href="https://arxiv.org/abs/1611.07004">Image to Image Translation</a></li>
<li><a href="https://arxiv.org/abs/1609.04802">Increasing Image Resolution</a></li>
<li><a href="https://arxiv.org/abs/1511.06380">Predicting Next Video Frame</a></li>
</ul>
<h2 id="notable-papers-on-gans">Notable Papers on GANs</h2>
<ul>
<li>[Generative Adversarial Nets] <a href="https://arxiv.org/abs/1406.2661">[Paper]</a>
<a href="https://github.com/goodfeli/adversarial">[Code]</a>(Ian Goodfellow’s breakthrough paper)</li>
</ul>
<h3 id="unclassified-papers--resources">Unclassified Papers &amp; Resources</h3>
<ul>
<li>
<p><a href="https://github.com/soumith/ganhacks">GAN Hacks: How to Train a GAN? Tips and tricks to make GANs work</a></p>
</li>
<li>
<p>Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks] <a href="https://arxiv.org/abs/1506.05751">[Paper]</a><a href="https://github.com/facebook/eyescream">[Code]</a></p>
</li>
<li>
<p>[Adversarial Autoencoders] <a href="https://arxiv.org/abs/1511.05644">[Paper]</a><a href="https://github.com/musyoku/adversarial-autoencoder">[Code]</a></p>
</li>
<li>
<p>[Generating Images with Perceptual Similarity Metrics based on Deep Networks] <a href="https://arxiv.org/pdf/1602.02644v2.pdf">[Paper]</a></p>
</li>
<li>
<p>[Generating images with recurrent adversarial networks] <a href="https://arxiv.org/abs/1602.05110">[Paper]</a><a href="https://github.com/ofirnachum/sequence_gan">[Code]</a></p>
</li>
<li>
<p>[Generative Visual Manipulation on the Natural Image Manifold] <a href="https://people.eecs.berkeley.edu/~junyanz/projects/gvm/eccv16_gvm.pdf">[Paper]</a><a href="https://github.com/junyanz/iGAN">[Code]</a></p>
</li>
<li>
<p>[Learning What and Where to Draw] <a href="http://www.scottreed.info/files/nips2016.pdf">[Paper]</a><a href="https://github.com/reedscot/nips2016">[Code]</a></p>
</li>
<li>
<p>[Adversarial Training for Sketch Retrieval] <a href="https://link.springer.com/chapter/10.1007/978-3-319-46604-0_55">[Paper]</a></p>
</li>
<li>
<p>[Generative Image Modeling using Style and Structure Adversarial Networks] <a href="https://arxiv.org/pdf/1603.05631.pdf">[Paper]</a><a href="https://github.com/xiaolonw/ss-gan">[Code]</a></p>
</li>
<li>
<p>[Generative Adversarial Networks as Variational Training of Energy Based Models] <a href="http://www.mathpubs.com/detail/1611.01799v1/Generative-Adversarial-Networks-as-Variational-Training-of-Energy-Based-Models">[Paper]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Synthesizing the preferred inputs for neurons in neural networks via deep generator networks] <a href="https://arxiv.org/pdf/1605.09304v5.pdf">[Paper]</a><a href="https://github.com/Evolving-AI-Lab/synthesizing">[Code]</a></p>
</li>
<li>
<p>[SalGAN: Visual Saliency Prediction with Generative Adversarial Networks] <a href="https://arxiv.org/abs/1701.01081">[Paper]</a><a href="https://github.com/imatge-upc/saliency-salgan-2017">[Code]</a></p>
</li>
<li>
<p>[Adversarial Feature Learning] <a href="https://arxiv.org/abs/1605.09782">[Paper]</a></p>
</li>
</ul>
<h3 id="generating-high-quality-images">Generating High-Quality Images</h3>
<ul>
<li>
<p>[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] <a href="https://arxiv.org/abs/1511.06434">[Paper]</a><a href="https://github.com/jacobgil/keras-dcgan">[Code]</a>(Gan with convolutional networks)(ICLR)</p>
</li>
<li>
<p>[Generative Adversarial Text to Image Synthesis] <a href="https://arxiv.org/abs/1605.05396">[Paper]</a><a href="https://github.com/reedscot/icml2016">[Code]</a><a href="https://github.com/paarthneekhara/text-to-image">[Code]</a></p>
</li>
<li>
<p>[Improved Techniques for Training GANs] <a href="https://arxiv.org/abs/1606.03498">[Paper]</a><a href="https://github.com/openai/improved-gan">[Code]</a>(Goodfellow’s paper)</p>
</li>
<li>
<p>[Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space] <a href="https://arxiv.org/abs/1612.00005v1">[Paper]</a><a href="https://github.com/Evolving-AI-Lab/ppgn">[Code]</a></p>
</li>
<li>
<p>[StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks] <a href="https://arxiv.org/pdf/1612.03242v1.pdf">[Paper]</a><a href="https://github.com/hanzhanggit/StackGAN">[Code]</a></p>
</li>
<li>
<p>[Improved Training of Wasserstein GANs] <a href="https://arxiv.org/abs/1704.00028">[Paper]</a><a href="https://github.com/igul222/improved_wgan_training">[Code]</a></p>
</li>
<li>
<p>[Boundary Equibilibrium Generative Adversarial Networks Implementation in Tensorflow] <a href="https://arxiv.org/abs/1703.10717">[Paper]</a><a href="https://github.com/artcg/BEGAN">[Code]</a></p>
</li>
<li>
<p>[Progressive Growing of GANs for Improved Quality, Stability, and Variation ] <a href="http://research.nvidia.com/publication/2017-10_Progressive-Growing-of">[Paper]</a><a href="https://github.com/tkarras/progressive_growing_of_gans">[Code]</a></p>
</li>
</ul>
<h3 id="semi-supervised-learning">Semi-supervised learning</h3>
<ul>
<li>
<p>[Adversarial Training Methods for Semi-Supervised Text Classification] <a href="https://arxiv.org/abs/1605.07725">[Paper]</a><a href="https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/adversarial-text-classification.md">[Note]</a>( Ian Goodfellow Paper)</p>
</li>
<li>
<p>[Improved Techniques for Training GANs] <a href="https://arxiv.org/abs/1606.03498">[Paper]</a><a href="https://github.com/openai/improved-gan">[Code]</a>(Goodfellow’s paper)</p>
</li>
<li>
<p>[Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks] <a href="https://arxiv.org/abs/1511.06390">[Paper]</a>(ICLR)</p>
</li>
<li>
<p>[Semi-Supervised QA with Generative Domain-Adaptive Nets] <a href="https://arxiv.org/abs/1702.02206">[Paper]</a>(ACL 2017)</p>
</li>
</ul>
<h3 id="ensembles">Ensembles</h3>
<ul>
<li>[AdaGAN: Boosting Generative Models] <a href="https://arxiv.org/abs/1701.02386">[Paper]</a>[[Code]]（Google Brain）</li>
</ul>
<h3 id="clustering">Clustering</h3>
<ul>
<li>[Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks] <a href="https://arxiv.org/abs/1511.06390">[Paper]</a>(ICLR)</li>
</ul>
<h3 id="image-blending">Image blending</h3>
<ul>
<li>[GP-GAN: Towards Realistic High-Resolution Image Blending] <a href="https://arxiv.org/abs/1703.07195">[Paper]</a><a href="https://github.com/wuhuikai/GP-GAN">[Code]</a></li>
</ul>
<h3 id="image-inpainting">Image Inpainting</h3>
<ul>
<li>
<p>[Semantic Image Inpainting with Perceptual and Contextual Losses] <a href="https://arxiv.org/abs/1607.07539">[Paper]</a><a href="https://github.com/bamos/dcgan-completion.tensorflow">[Code]</a>(CVPR 2017)</p>
</li>
<li>
<p>[Context Encoders: Feature Learning by Inpainting] <a href="https://arxiv.org/abs/1604.07379">[Paper]</a><a href="https://github.com/jazzsaxmafia/Inpainting">[Code]</a></p>
</li>
<li>
<p>[Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks] <a href="https://arxiv.org/abs/1611.06430v1">[Paper]</a></p>
</li>
<li>
<p>[Generative face completion] <a href="https://drive.google.com/file/d/0B8_MZ8a8aoSeenVrYkpCdnFRVms/edit">[Paper]</a><a href="https://github.com/Yijunmaverick/GenerativeFaceCompletion">[Code]</a>(CVPR2017)</p>
</li>
<li>
<p>[Globally and Locally Consistent Image Completion] <a href="http://hi.cs.waseda.ac.jp/~iizuka/projects/completion/en/">[MainPAGE]</a>(SIGGRAPH 2017)</p>
</li>
</ul>
<h3 id="joint-probability">Joint Probability</h3>
<ul>
<li>[Adversarially Learned Inference]<a href="https://arxiv.org/abs/1606.00704">[Paper]</a><a href="https://github.com/IshmaelBelghazi/ALI">[Code]</a></li>
</ul>
<h3 id="super-resolution">Super-Resolution</h3>
<ul>
<li>
<p>[Image super-resolution through deep learning ]<a href="https://github.com/david-gpu/srez">[Code]</a>(Just for face dataset)</p>
</li>
<li>
<p>[Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network] <a href="https://arxiv.org/abs/1609.04802">[Paper]</a><a href="https://github.com/leehomyc/Photo-Realistic-Super-Resoluton">[Code]</a>（Using Deep residual network）</p>
</li>
<li>
<p>[EnhanceGAN] <a href="https://medium.com/@richardherbert/faces-from-noise-super-enhancing-8x8-images-with-enhancegan-ebda015bb5e0#.io6pskvin">Docs</a>[[Code]]</p>
</li>
</ul>
<h3 id="de-occlusion">De-occlusion</h3>
<ul>
<li>[Robust LSTM-Autoencoders for Face De-Occlusion in the Wild] <a href="https://arxiv.org/abs/1612.08534">[Paper]</a></li>
</ul>
<h3 id="semantic-segmentation">Semantic Segmentation</h3>
<ul>
<li>
<p>[Adversarial Deep Structural Networks for Mammographic Mass Segmentation] <a href="https://arxiv.org/abs/1612.05970">[Paper]</a><a href="https://github.com/wentaozhu/adversarial-deep-structural-networks">[Code]</a></p>
</li>
<li>
<p>[Semantic Segmentation using Adversarial Networks] <a href="https://arxiv.org/abs/1611.08408">[Paper]</a>（Soumith’s paper）</p>
</li>
</ul>
<h3 id="object-detection">Object Detection</h3>
<ul>
<li>
<p>[Perceptual generative adversarial networks for small object detection] <a href="https://arxiv.org/abs/1706.05274v2">[Paper]</a>(CVPR 2017)</p>
</li>
<li>
<p>[A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection] <a href="http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf">[Paper]</a><a href="https://github.com/xiaolonw/adversarial-frcnn">[Code]</a>(CVPR2017)</p>
</li>
</ul>
<h3 id="rnn-gans">RNN-GANs</h3>
<ul>
<li>[C-RNN-GAN: Continuous recurrent neural networks with adversarial training] <a href="https://arxiv.org/abs/1611.09904">[Paper]</a><a href="https://github.com/olofmogren/c-rnn-gan">[Code]</a></li>
</ul>
<h3 id="conditional-adversarial-nets">Conditional Adversarial Nets</h3>
<ul>
<li>
<p>[Conditional Generative Adversarial Nets] <a href="https://arxiv.org/abs/1411.1784">[Paper]</a><a href="https://github.com/zhangqianhui/Conditional-Gans">[Code]</a></p>
</li>
<li>
<p>[InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets] <a href="https://arxiv.org/abs/1606.03657">[Paper]</a><a href="https://github.com/buriburisuri/supervised_infogan">[Code]</a><a href="https://github.com/openai/InfoGAN">[Code]</a></p>
</li>
<li>
<p>[Conditional Image Synthesis With Auxiliary Classifier GANs] <a href="https://arxiv.org/abs/1610.09585">[Paper]</a><a href="https://github.com/buriburisuri/ac-gan">[Code]</a>(GoogleBrain ICLR 2017)</p>
</li>
<li>
<p>[Pixel-Level Domain Transfer] <a href="https://arxiv.org/pdf/1603.07442v2.pdf">[Paper]</a><a href="https://github.com/fxia22/pldtgan">[Code]</a></p>
</li>
<li>
<p>[Invertible Conditional GANs for image editing] <a href="https://arxiv.org/abs/1611.06355">[Paper]</a><a href="https://github.com/Guim3/IcGAN">[Code]</a></p>
</li>
<li>
<p>[Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space] <a href="https://arxiv.org/abs/1612.00005v1">[Paper]</a><a href="https://github.com/Evolving-AI-Lab/ppgn">[Code]</a></p>
</li>
<li>
<p>[StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks] <a href="https://arxiv.org/pdf/1612.03242v1.pdf">[Paper]</a><a href="https://github.com/hanzhanggit/StackGAN">[Code]</a></p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1801.07736">MaskGAN: Better Text Generation via Filling in the <strong>__</strong></a> Goodfellow et al</p>
</li>
</ul>
<h3 id="video-prediction--generation">Video Prediction &amp; Generation</h3>
<ul>
<li>
<p>[Deep multi-scale video prediction beyond mean square error] <a href="https://arxiv.org/abs/1511.05440">[Paper]</a><a href="https://github.com/dyelax/Adversarial_Video_Generation">[Code]</a>(Yann LeCun’s paper)</p>
</li>
<li>
<p>[Generating Videos with Scene Dynamics] <a href="https://arxiv.org/abs/1609.02612">[Paper]</a><a href="http://web.mit.edu/vondrick/tinyvideo/">[Web]</a><a href="https://github.com/cvondrick/videogan">[Code]</a></p>
</li>
<li>
<p>[MoCoGAN: Decomposing Motion and Content for Video Generation] <a href="https://arxiv.org/abs/1707.04993">[Paper]</a></p>
</li>
</ul>
<h3 id="texture-synthesis--style-transfer">Texture Synthesis &amp; Style Transfer</h3>
<ul>
<li>[Precomputed real-time texture synthesis with markovian generative adversarial networks] <a href="https://arxiv.org/abs/1604.04382">[Paper]</a><a href="https://github.com/chuanli11/MGANs">[Code]</a>(ECCV 2016)</li>
</ul>
<h3 id="image-translation">Image Translation</h3>
<ul>
<li>
<p>[Unsupervised cross-domain image generation] <a href="https://arxiv.org/abs/1611.02200">[Paper]</a><a href="https://github.com/yunjey/domain-transfer-network">[Code]</a></p>
</li>
<li>
<p>[Image-to-image translation using conditional adversarial nets] <a href="https://arxiv.org/pdf/1611.07004v1.pdf">[Paper]</a><a href="https://github.com/phillipi/pix2pix">[Code]</a><a href="https://github.com/yenchenlin/pix2pix-tensorflow">[Code]</a></p>
</li>
<li>
<p>[Learning to Discover Cross-Domain Relations with Generative Adversarial Networks] <a href="https://arxiv.org/abs/1703.05192">[Paper]</a><a href="https://github.com/carpedm20/DiscoGAN-pytorch">[Code]</a></p>
</li>
<li>
<p>[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks] <a href="https://junyanz.github.io/CycleGAN/">[Paper]</a><a href="https://github.com/junyanz/CycleGAN">[Code]</a></p>
</li>
<li>
<p>[CoGAN: Coupled Generative Adversarial Networks] <a href="https://arxiv.org/abs/1606.07536">[Paper]</a><a href="https://github.com/andrewliao11/CoGAN-tensorflow">[Code]</a>(NIPS 2016)</p>
</li>
<li>
<p>[Unsupervised Image-to-Image Translation with Generative Adversarial Networks] <a href="https://arxiv.org/pdf/1701.02676.pdf">[Paper]</a></p>
</li>
<li>
<p>[Unsupervised Image-to-Image Translation Networks] <a href="https://arxiv.org/abs/1703.00848">[Paper]</a></p>
</li>
<li>
<p>[Triangle Generative Adversarial Networks] <a href="https://arxiv.org/abs/1709.06548">[Paper]</a></p>
</li>
</ul>
<h3 id="gan-theory">GAN Theory</h3>
<ul>
<li>
<p>[Energy-based generative adversarial network] <a href="https://arxiv.org/pdf/1609.03126v2.pdf">[Paper]</a><a href="https://github.com/buriburisuri/ebgan">[Code]</a>(Lecun paper)</p>
</li>
<li>
<p>[Improved Techniques for Training GANs] <a href="https://arxiv.org/abs/1606.03498">[Paper]</a><a href="https://github.com/openai/improved-gan">[Code]</a>(Goodfellow’s paper)</p>
</li>
<li>
<p>[Mode Regularized Generative Adversarial Networks] <a href="https://openreview.net/pdf?id=HJKkY35le">[Paper]</a>(Yoshua Bengio , ICLR 2017)</p>
</li>
<li>
<p>[Improving Generative Adversarial Networks with Denoising Feature Matching] <a href="https://openreview.net/pdf?id=S1X7nhsxl">[Paper]</a><a href="https://github.com/hvy/chainer-gan-denoising-feature-matching">[Code]</a>(Yoshua Bengio , ICLR 2017)</p>
</li>
<li>
<p>[Sampling Generative Networks] <a href="https://arxiv.org/abs/1609.04468">[Paper]</a><a href="https://github.com/dribnet/plat">[Code]</a></p>
</li>
<li>
<p>[How to train Gans] <a href="https://github.com/soumith/ganhacks#authors">[Docu]</a></p>
</li>
<li>
<p>[Towards Principled Methods for Training Generative Adversarial Networks] <a href="http://openreview.net/forum?id=Hk4_qw5xe">[Paper]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Unrolled Generative Adversarial Networks] <a href="https://arxiv.org/abs/1611.02163">[Paper]</a><a href="https://github.com/poolio/unrolled_gan">[Code]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Least Squares Generative Adversarial Networks] <a href="https://arxiv.org/abs/1611.04076">[Paper]</a><a href="https://github.com/pfnet-research/chainer-LSGAN">[Code]</a>(ICCV 2017)</p>
</li>
<li>
<p>[Wasserstein GAN] <a href="https://arxiv.org/abs/1701.07875">[Paper]</a><a href="https://github.com/martinarjovsky/WassersteinGAN">[Code]</a></p>
</li>
<li>
<p>[Improved Training of Wasserstein GANs] <a href="https://arxiv.org/abs/1704.00028">[Paper]</a><a href="https://github.com/igul222/improved_wgan_training">[Code]</a>(The improve of wgan)</p>
</li>
<li>
<p>[Towards Principled Methods for Training Generative Adversarial Networks] <a href="https://arxiv.org/abs/1701.04862">[Paper]</a></p>
</li>
<li>
<p>[Generalization and Equilibrium in Generative Adversarial Nets] <a href="https://arxiv.org/abs/1703.00573">[Paper]</a>（ICML 2017）</p>
</li>
</ul>
<h3 id="3-dimensional-gans">3-Dimensional GANs</h3>
<ul>
<li>
<p>[Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling] <a href="https://arxiv.org/abs/1610.07584">[Paper]</a><a href="http://3dgan.csail.mit.edu/">[Web]</a><a href="https://github.com/zck119/3dgan-release">[Code]</a>(2016 NIPS)</p>
</li>
<li>
<p>[Transformation-Grounded Image Generation Network for Novel 3D View Synthesis] <a href="http://www.cs.unc.edu/%7Eeunbyung/tvsn/">[Web]</a>(CVPR 2017)</p>
</li>
</ul>
<h3 id="music">Music</h3>
<ul>
<li>[MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation using 1D and 2D Conditions] <a href="https://arxiv.org/abs/1703.10847">[Paper]</a><a href="https://richardyang40148.github.io/TheBlog/midinet_arxiv_demo.html">[HOMEPAGE]</a></li>
</ul>
<h3 id="face-generation--editing">Face Generation &amp; Editing</h3>
<ul>
<li>
<p>[Autoencoding beyond pixels using a learned similarity metric] <a href="https://arxiv.org/abs/1512.09300">[Paper]</a><a href="https://github.com/andersbll/autoencoding_beyond_pixels">[Code]</a><a href="https://github.com/zhangqianhui/vae-gan-tensorflow">[Tensorflow code]</a></p>
</li>
<li>
<p>[Coupled Generative Adversarial Networks] <a href="http://mingyuliu.net/">[Paper]</a><a href="https://github.com/mingyuliutw/CoGAN">[Caffe Code]</a><a href="https://github.com/andrewliao11/CoGAN-tensorflow">[Tensorflow Code]</a>（NIPS）</p>
</li>
<li>
<p>[Invertible Conditional GANs for image editing] <a href="https://drive.google.com/file/d/0B48XS5sLi1OlRkRIbkZWUmdoQmM/view">[Paper]</a><a href="https://github.com/Guim3/IcGAN">[Code]</a></p>
</li>
<li>
<p>[Learning Residual Images for Face Attribute Manipulation] <a href="https://arxiv.org/abs/1612.05363">[Paper]</a><a href="https://github.com/Zhongdao/FaceAttributeManipulation">[Code]</a>(CVPR 2017)</p>
</li>
<li>
<p>[Neural Photo Editing with Introspective Adversarial Networks] <a href="https://arxiv.org/abs/1609.07093">[Paper]</a><a href="https://github.com/ajbrock/Neural-Photo-Editor">[Code]</a>(ICLR 2017)</p>
</li>
<li>
<p>[Neural Face Editing with Intrinsic Image Disentangling] <a href="https://arxiv.org/abs/1704.04131">[Paper]</a>(CVPR 2017)</p>
</li>
<li>
<p>[GeneGAN: Learning Object Transfiguration and Attribute Subspace from Unpaired Data ] <a href="https://arxiv.org/abs/1705.04932">[Paper]</a>(BMVC 2017)<a href="https://github.com/Prinsphield/GeneGAN">[Code]</a></p>
</li>
<li>
<p>[Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis] <a href="https://arxiv.org/abs/1704.04086">[Paper]</a>(ICCV 2017)</p>
</li>
</ul>
<h3 id="for-discrete-distributions">For Discrete Distributions</h3>
<ul>
<li>
<p>[Maximum-Likelihood Augmented Discrete Generative Adversarial Networks] <a href="https://arxiv.org/abs/1702.07983v1">[Paper]</a></p>
</li>
<li>
<p>[Boundary-Seeking Generative Adversarial Networks] <a href="https://arxiv.org/abs/1702.08431">[Paper]</a></p>
</li>
<li>
<p>[GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution] <a href="https://arxiv.org/abs/1611.04051">[Paper]</a></p>
</li>
</ul>
<h3 id="improving-classification--recognition">Improving Classification &amp; Recognition</h3>
<ul>
<li>
<p>[Generative OpenMax for Multi-Class Open Set Classification] <a href="https://arxiv.org/pdf/1707.07418.pdf">[Paper]</a>(BMVC 2017)</p>
</li>
<li>
<p>[Controllable Invariance through Adversarial Feature Learning] <a href="https://arxiv.org/abs/1705.11122">[Paper]</a><a href="https://github.com/github-pengge/adversarial_invariance_feature_learning">[Code]</a>(NIPS 2017)</p>
</li>
<li>
<p>[Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro] <a href="https://arxiv.org/abs/1701.07717">[Paper]</a><a href="https://github.com/layumi/Person-reID_GAN">[Code]</a> (ICCV2017)</p>
</li>
<li>
<p>[Learning from Simulated and Unsupervised Images through Adversarial Training] <a href="https://arxiv.org/abs/1612.07828">[Paper]</a><a href="https://github.com/carpedm20/simulated-unsupervised-tensorflow">[Code]</a>（Apple paper, CVPR 2017 Best Paper）</p>
</li>
</ul>
<h3 id="projects">Projects</h3>
<ul>
<li>
<p>[cleverhans] <a href="https://github.com/openai/cleverhans">[Code]</a>(A library for benchmarking vulnerability to adversarial examples)</p>
</li>
<li>
<p>[reset-cppn-gan-tensorflow] <a href="https://github.com/hardmaru/resnet-cppn-gan-tensorflow">[Code]</a>(Using Residual Generative Adversarial Networks and Variational Auto-encoder techniques to produce high-resolution images)</p>
</li>
<li>
<p>[HyperGAN] <a href="https://github.com/255bits/HyperGAN">[Code]</a>(Open source GAN focused on scale and usability)</p>
</li>
</ul>
<h3 id="tutorials">Tutorials</h3>
<ul>
<li>
<p>[1] <a href="http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf">Ian Goodfellow’s GAN Slides</a> (NIPS Goodfellow Slides)<a href="https://c.m.163.com/news/a/C7UE2MLT0511AQHO.html?spss=newsapp&amp;spsw=1">[Chinese Trans]</a><a href="https://arxiv.org/pdf/1701.00160v1.pdf">details</a></p>
</li>
<li>
<p>[2] <a href="https://drive.google.com/file/d/0BxKBnD5y2M8NbzBUbXRwUDBZOVU/view">PDF</a>(NIPS Lecun Slides)</p>
</li>
<li>
<p>[3] <a href="https://sites.google.com/view/iccv-2017-gans/schedule">ICCV 2017 Tutorial About GANS</a></p>
</li>
</ul>

-----------------

**Applied Other**

- Adversarial Generation of Natural Language [[arXiv]](https://arxiv.org/abs/1705.10929)
- Adversarial Ranking for Language Generation [[arXiv]](https://arxiv.org/abs/1705.11001)
- Adversarial Training Methods for Semi-Supervised Text Classification [[arXiv]](https://arxiv.org/abs/1605.07725) [[Paper]](https://c4209155-a-62cb3a1a-s-sites.googlegroups.com/site/nips2016adversarial/WAT16_paper_12.pdf)
- A Generative Model for Volume Rendering [[arXiv]](A Generative Model for Volume Rendering)
- ChemGAN challenge for drug discovery: can AI reproduce natural chemical diversity? [[arXiv]](https://arxiv.org/abs/1708.08227)
- Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN [[arXiv]](https://arxiv.org/abs/1702.05983)
- Generating Multi-label Discrete Electronic Health Records using Generative Adversarial Networks [[arXiv]](https://arxiv.org/abs/1703.06490)
- Language Generation with Recurrent Generative Adversarial Networks without Pre-training [[arXiv]](https://arxiv.org/abs/1706.01399)
- Learning to Protect Communications with Adversarial Neural Cryptography [[arXiv]](https://arxiv.org/abs/1610.06918) [[Blog]](https://blog.acolyer.org/2017/02/10/learning-to-protect-communications-with-adversarial-neural-cryptography/)
- Long Text Generation via Adversarial Training with Leaked Information [[arXiv]](https://arxiv.org/abs/1709.08624)
- MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation using 1D and 2D Conditions [[arXiv]](https://arxiv.org/abs/1703.10847)
- MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks [[arXiv]](https://arxiv.org/abs/1709.06298)
- Reconstruction of three-dimensional porous media using generative adversarial neural networks [[arXiv]](https://arxiv.org/abs/1704.03225) [[Code]](https://github.com/LukasMosser/PorousMediaGan)
- SEGAN: Speech Enhancement Generative Adversarial Network [[arXiv]](https://arxiv.org/abs/1703.09452)
- Semi-supervised Learning of Compact Document Representations with Deep Networks [[Paper]](http://www.cs.nyu.edu/~ranzato/publications/ranzato-icml08.pdf)
- SSGAN: Secure Steganography Based on Generative Adversarial Networks [[arXiv]](https://arxiv.org/abs/1707.01613)
- Steganographic Generative Adversarial Networks [[arXiv]](https://arxiv.org/abs/1703.05502)
- Towards Grounding Conceptual Spaces in Neural Representations [[arXiv]](https://arxiv.org/abs/1706.04825)


----------------
